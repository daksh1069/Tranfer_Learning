{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model ko train karo 0-4 detect kanr ke liye,,,, but 5-9 ko classify karna hai - \n",
    "# and to your surprise you'd realise accuracy would still be pretty good . \n",
    "# CNN - Auto Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google etc. has already trained the neural networks on a lot of data and it's a \n",
    "# state of the art architecture... hence we can transfer that google training model's weight and test it on our data... \n",
    "# You'd realise the accurscy is pretty high.. Image.net can be used for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Conv2D, Flatten, Activation, MaxPool2D, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 20000\n",
    "x_train1 = []\n",
    "y_train1 = []\n",
    "x_test1 = []\n",
    "y_test1 = []\n",
    "\n",
    "x_train2 = []\n",
    "y_train2 = []\n",
    "x_test2 = []\n",
    "y_test2 = []\n",
    "\n",
    "\n",
    "# Training Data\n",
    "for i in range(m):\n",
    "    if y_train[i]<5:\n",
    "        x_train1.append(x_train[i]/255) #Normalising Pixel Values\n",
    "        y_train1.append(y_train[i])\n",
    "    else:\n",
    "        x_train2.append(x_train[i]/255) # Normalising Pixel Values\n",
    "        y_train2.append(y_train[i])\n",
    "        \n",
    "        \n",
    "        \n",
    "# Testing Data\n",
    "m2 = 5000\n",
    "for i in range(m2):\n",
    "    if y_test[i]<5:\n",
    "        x_test1.append(x_test[i]/255) #Normalising Pixel Values\n",
    "        y_test1.append(y_test[i])\n",
    "    else:\n",
    "        x_test2.append(x_test[i]/255) # Normalising Pixel Values (0-255 hai values But Deep learning Lagaenge toh hi toh baat banegi)\n",
    "        y_test2.append(y_test[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = np.asarray(x_train1).reshape(-1,28,28,1)\n",
    "X_test1 = np.asarray(x_test1).reshape(-1,28,28,1)\n",
    "\n",
    "X_train2 = np.asarray(x_train2).reshape(-1,28,28,1)\n",
    "X_test2 = np.asarray(x_test2).reshape(-1,28,28,1)\n",
    "\n",
    "Y_train1 = np_utils.to_categorical(np.asarray(y_train1))\n",
    "Y_test1 = np_utils.to_categorical(np.asarray(y_test1))\n",
    "\n",
    "Y_train2 = np_utils.to_categorical(np.asarray(y_train2))\n",
    "Y_test2 = np_utils.to_categorical(np.asarray(y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10225, 28, 28, 1)\n",
      "(2561, 28, 28, 1)\n",
      "(10225, 5)\n",
      "(2561, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X_train1.shape)\n",
    "print(X_test1.shape)\n",
    "\n",
    "print(Y_train1.shape)\n",
    "print(Y_test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9775, 28, 28, 1)\n",
      "(2439, 28, 28, 1)\n",
      "(9775, 10)\n",
      "(2439, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train2.shape)\n",
    "print(X_test2.shape)\n",
    "\n",
    "print(Y_train2.shape)\n",
    "print(Y_test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 20, 20, 16)        12816     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 10, 10, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 8, 8, 8)           1160      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 81,117\n",
      "Trainable params: 81,117\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32,5,input_shape=(28,28,1),activation=\"relu\"))\n",
    "model.add(Conv2D(16,5,activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size = (2,2)))\n",
    "model.add(Conv2D(8,3,activation=\"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation(\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "                loss=\"categorical_crossentropy\",\n",
    "                optimizer=\"adam\",\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10225 samples, validate on 2561 samples\n",
      "Epoch 1/10\n",
      " - 18s - loss: 0.2993 - accuracy: 0.9018 - val_loss: 0.0596 - val_accuracy: 0.9840\n",
      "Epoch 2/10\n",
      " - 17s - loss: 0.0707 - accuracy: 0.9794 - val_loss: 0.0400 - val_accuracy: 0.9887\n",
      "Epoch 3/10\n",
      " - 19s - loss: 0.0550 - accuracy: 0.9823 - val_loss: 0.0289 - val_accuracy: 0.9922\n",
      "Epoch 4/10\n",
      " - 19s - loss: 0.0410 - accuracy: 0.9859 - val_loss: 0.0359 - val_accuracy: 0.9879\n",
      "Epoch 5/10\n",
      " - 19s - loss: 0.0343 - accuracy: 0.9883 - val_loss: 0.0176 - val_accuracy: 0.9938\n",
      "Epoch 6/10\n",
      " - 19s - loss: 0.0276 - accuracy: 0.9909 - val_loss: 0.0149 - val_accuracy: 0.9953\n",
      "Epoch 7/10\n",
      " - 18s - loss: 0.0260 - accuracy: 0.9906 - val_loss: 0.0223 - val_accuracy: 0.9945\n",
      "Epoch 8/10\n",
      " - 20s - loss: 0.0211 - accuracy: 0.9927 - val_loss: 0.0133 - val_accuracy: 0.9945\n",
      "Epoch 9/10\n",
      " - 18s - loss: 0.0159 - accuracy: 0.9937 - val_loss: 0.0170 - val_accuracy: 0.9934\n",
      "Epoch 10/10\n",
      " - 16s - loss: 0.0169 - accuracy: 0.9949 - val_loss: 0.0097 - val_accuracy: 0.9973\n",
      "0:03:05.346905\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "model.fit(X_train1,Y_train1,\n",
    "         nb_epoch = 10,\n",
    "          shuffle=True,\n",
    "          batch_size=100,\n",
    "          verbose=2,\n",
    "          validation_data=(X_test1,Y_test1))\n",
    "end = datetime.datetime.now()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers[:6]:\n",
    "    layer.trainable =False\n",
    "\n",
    "for layer in model.layers:\n",
    "    print(layer.trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tranfer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 20, 20, 16)        12816     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 10, 10, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 8, 8, 8)           1160      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 81,762\n",
      "Trainable params: 66,954\n",
      "Non-trainable params: 14,808\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tranfer_model = Sequential(model.layers[:6])\n",
    "tranfer_model.add(Dense(128))\n",
    "tranfer_model.add(Activation(\"relu\"))\n",
    "\n",
    "tranfer_model.add(Dense(10))\n",
    "tranfer_model.add(Activation(\"softmax\"))\n",
    "tranfer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tranfer_model.compile(\n",
    "                loss=\"categorical_crossentropy\",\n",
    "                optimizer=\"adam\",\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9775 samples, validate on 2439 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 0.3504 - accuracy: 0.8907 - val_loss: 0.1112 - val_accuracy: 0.9656\n",
      "Epoch 2/10\n",
      " - 4s - loss: 0.1005 - accuracy: 0.9692 - val_loss: 0.0793 - val_accuracy: 0.9746\n",
      "Epoch 3/10\n",
      " - 4s - loss: 0.0764 - accuracy: 0.9745 - val_loss: 0.0664 - val_accuracy: 0.9795\n",
      "Epoch 4/10\n",
      " - 4s - loss: 0.0713 - accuracy: 0.9763 - val_loss: 0.0718 - val_accuracy: 0.9779\n",
      "Epoch 5/10\n",
      " - 4s - loss: 0.0650 - accuracy: 0.9794 - val_loss: 0.0578 - val_accuracy: 0.9840\n",
      "Epoch 6/10\n",
      " - 4s - loss: 0.0591 - accuracy: 0.9792 - val_loss: 0.0540 - val_accuracy: 0.9861\n",
      "Epoch 7/10\n",
      " - 4s - loss: 0.0507 - accuracy: 0.9826 - val_loss: 0.0594 - val_accuracy: 0.9815\n",
      "Epoch 8/10\n",
      " - 4s - loss: 0.0475 - accuracy: 0.9859 - val_loss: 0.0479 - val_accuracy: 0.9848\n",
      "Epoch 9/10\n",
      " - 4s - loss: 0.0461 - accuracy: 0.9841 - val_loss: 0.0471 - val_accuracy: 0.9848\n",
      "Epoch 10/10\n",
      " - 4s - loss: 0.0439 - accuracy: 0.9863 - val_loss: 0.0440 - val_accuracy: 0.9840\n",
      "0:00:38.976768\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "tranfer_model.fit(X_train2,Y_train2,\n",
    "         nb_epoch = 10,\n",
    "          shuffle=True,\n",
    "          batch_size=100,\n",
    "          verbose=2,\n",
    "          validation_data=(X_test2,Y_test2))\n",
    "end = datetime.datetime.now()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
